---
pagetitle: The user's view of the solving process
shorttitle: Solving
---

A declarative program lets you state a problem without having to state how to solve it.  Much of the point of using a declarative language is that you don't have to think about how to solve it; that's not your problem, it's the solver's problem.

That said, languages like Step, which are derived from classical logic programming languages like Prolog[^1], share a common solver strategy that can miss solutions in certain circumstances.[^2] They do this for three reasons:

* The strategy is fast
* The strategy is simple and easy to remember
* The programmer can generally use their knowledge of the strategy to work around many of its pitfalls.

As a result, it pays to understand a little of what's going on under the hood, starting with what it means for something to be a solution.  So we'll talk about that first, and then give a somewhat more detailed description for those who are more technically inclined.  We will stop well short of describing how to build your own solver, however.  For that, see [Part II](part_ii).

We need to explain two different things:

* How does the system know which methods to select?
* How does the matching of calls to methods work?

We'll discuss these next.

## Endnotes

[^1]: Esoteric: I use the term "classical" logic programming language to distinguish languages like Step and [Prolog](https://en.wikipedia.org/wiki/Prolog) from [answer set programming](https://en.wikipedia.org/wiki/Answer_set_programming) (ASP). Some proponents of ASP no longer consider classical languages like Prolog to be logic programming.  So I'll adopt the term "classical" to mean the Prolog-like languages whose solvers are based on [SLD resolution](https://en.wikipedia.org/wiki/SLD_resolution), in contrast to ASP whose solvers use a radically different class of algorithms based in part on [SAT solving](https://en.wikipedia.org/wiki/SAT_solver).

[^2]: The technical term for this is that they are **incomplete**.